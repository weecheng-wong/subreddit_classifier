{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488f6516",
   "metadata": {},
   "source": [
    "# Project 3 : Web APIs & NLP - Classification of subreddit posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9feedba",
   "metadata": {},
   "source": [
    "## Part 2 - Introduction & data scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc619b",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eab269",
   "metadata": {},
   "source": [
    "In this day and age, the ease of setting up trading accounts with the many platforms available has resulted in high accessibility of trading stocks and crytocurrencies by the average joe.\n",
    "\n",
    "As a trading firm, we need to keep abreast of developments and discussions in platforms like Reddit to understand the prevailing trading sentiments in the current volatile environment. We aim to sieve out trading trends, sentiments through analyzing Reddit posts to support two of our most important trading desks - equities and crytocurrencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7bcb1b",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d40355",
   "metadata": {},
   "source": [
    "As a new investment firm with 2 main trading desks (one for traditional securities and one for crytocurrency), we aim to develop a tool to analyze the top trending topics in equities and crytocurrencies. In doing so, we could explore if there may be any correlation between any specific trending topics and a stock ticker or cryptocurrency, to support the firm in taking up data-informed trading positions.\n",
    "\n",
    "The idea is to develop a classification model that leverages on natural language programming (NLP) to identify and classify content into the categories of 'investing' vs. 'crytocurrency'.\\\n",
    "This is no mean feat, as it is expected that there are likely parallels between r/investing and r/cryptocurrency since they revolves around trading. Their uniqueness is exactly what we are keen to find out, and part of the deliverables of this undertaking.\n",
    "\n",
    "Performance metrics that will be part of the success criteria are:\\\n",
    "(We have specified in the binary classification, 1 or positive refers to r/investing category while 0 or negative refers to r/cryptocurrency category)\n",
    "- accuracy or how well the model is able to make correct classification\n",
    "- sensitivity (true positive rate) or how well the model is able to make correct classification as an r/investing topic\n",
    "- specificity (true negative rate) or how well the model is able to make correct classification as a r/cryptocurrency topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b32805",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60100b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e3f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config to display all\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b88c8",
   "metadata": {},
   "source": [
    "## Automated data scraping from Reddit via pushshift.api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf96207",
   "metadata": {},
   "source": [
    "The two chosen subreddits are \"r/investing\" and \"r/CryptoCurrency\".\\\n",
    "Define a function to extract the requisite data from the said subreddits and also for a specified timeframe.\\\n",
    "Based on the initial pre-scraping data acquaintance step in the previous notebook, there are some steps which are helpful to sieve out posts that are either 'removed' or 'deleted'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451dd4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function builds a get pushshift data for posts\n",
    "# adapted from https://colab.research.google.com/drive/1biLcXeHs8yZD1x9f3gv-cNJXEq7tpyoO?usp=sharing#scrollTo=mDma-H_k0frf\n",
    "\n",
    "def get_push_shift_data(subreddit, end_date_unix):\n",
    "    \n",
    "    # push shift URL endpoints\n",
    "    url ='https://api.pushshift.io/reddit/search/submission'\n",
    "    \n",
    "    # define parameters for the posts\n",
    "    params = {\n",
    "        'subreddit':subreddit,\n",
    "        'size':100,\n",
    "        'before': end_date_unix,\n",
    "    }\n",
    "    \n",
    "    # get the response\n",
    "    response = requests.get(url, params)\n",
    "    \n",
    "    # in the event of error due to time out, etc, pause for 1 second and make a new request\n",
    "    while response.status_code != 200:\n",
    "        time.sleep(1)\n",
    "        response = requests.get(url, params)\n",
    "    \n",
    "    # define the JSON data to a variable\n",
    "    data = response.json()\n",
    "    \n",
    "    # define the posts in the data\n",
    "    posts = data['data']\n",
    "    \n",
    "    # returns the list of posts \n",
    "    return posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6dd05",
   "metadata": {},
   "source": [
    "This function extracts the relevant columns from the reddit data as well as omit rows (posts) that have been removed by reddit, moderator or simply deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6666d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to extract the posts from eash JSON result, while eliminating posts removed by moderator\n",
    "# returns each extracted post as a post dictionary\n",
    "\n",
    "def extract_posts(data_posts):\n",
    "    \n",
    "    # generate a dict\n",
    "    post = {}\n",
    "    \n",
    "    # filter out only posts that have made it to reddit, i.e. not removed by reddit or moderator, not deleted posts\n",
    "    removed = data_posts['is_crosspostable']\n",
    "    \n",
    "    if removed is True:\n",
    "        selftext = data_posts['selftext']\n",
    "        if selftext != '':\n",
    "    \n",
    "            # extract columns of interest\n",
    "            post['title'] = data_posts['title']\n",
    "            post['create'] = data_posts['created_utc']\n",
    "            post['subreddit'] = data_posts['subreddit']\n",
    "            post['body'] = data_posts['selftext']\n",
    "            post['author'] = data_posts['author']\n",
    "            post['permalink'] = data_posts['permalink']\n",
    "            post['num_comments'] = data_posts['num_comments']\n",
    "            \n",
    "            # returns a dict of the extracted post\n",
    "            return post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6486587",
   "metadata": {},
   "source": [
    "This function returns the time the that post was created. This will be used specifically for the 100th post that each data collects, to reinitialize the next 100 posts to be scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa55d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_time(data_posts):\n",
    "    \n",
    "    # extract the time created for the post\n",
    "    time = data_posts['created_utc']\n",
    "    \n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6d20e",
   "metadata": {},
   "source": [
    "Defines the period of interest, before 25 Oct 2021 2359:59hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a0dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define date of interest before 25 Oct 2021 2359hrs SG time\n",
    "# equivalent epoch unix timestamp for end: 1635177599\n",
    "# reference from https://www.epochconverter.com/\n",
    "end = 1635177599"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d586ff6",
   "metadata": {},
   "source": [
    "### Scraping subreddit - investing posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a89580",
   "metadata": {},
   "source": [
    "Using a while loop to scrap posts from the particular subreddit that are not removed or deleted.\\\n",
    "To achieve at least 1000 posts target, have set 1200 target posts so that there remains a buffer for subsequent data cleaning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9804d340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looping 1 time(s). num of posts: 17\n",
      "looping 2 time(s). num of posts: 31\n",
      "looping 3 time(s). num of posts: 49\n",
      "looping 4 time(s). num of posts: 62\n",
      "looping 5 time(s). num of posts: 77\n",
      "looping 6 time(s). num of posts: 91\n",
      "looping 7 time(s). num of posts: 105\n",
      "looping 8 time(s). num of posts: 124\n",
      "looping 9 time(s). num of posts: 139\n",
      "looping 10 time(s). num of posts: 158\n",
      "looping 11 time(s). num of posts: 172\n",
      "looping 12 time(s). num of posts: 189\n",
      "looping 13 time(s). num of posts: 204\n",
      "looping 14 time(s). num of posts: 218\n",
      "looping 15 time(s). num of posts: 236\n",
      "looping 16 time(s). num of posts: 251\n",
      "looping 17 time(s). num of posts: 267\n",
      "looping 18 time(s). num of posts: 285\n",
      "looping 19 time(s). num of posts: 300\n",
      "looping 20 time(s). num of posts: 321\n",
      "looping 21 time(s). num of posts: 336\n",
      "looping 22 time(s). num of posts: 361\n",
      "looping 23 time(s). num of posts: 381\n",
      "looping 24 time(s). num of posts: 394\n",
      "looping 25 time(s). num of posts: 406\n",
      "looping 26 time(s). num of posts: 421\n",
      "looping 27 time(s). num of posts: 436\n",
      "looping 28 time(s). num of posts: 454\n",
      "looping 29 time(s). num of posts: 468\n",
      "looping 30 time(s). num of posts: 484\n",
      "looping 31 time(s). num of posts: 508\n",
      "looping 32 time(s). num of posts: 524\n",
      "looping 33 time(s). num of posts: 539\n",
      "looping 34 time(s). num of posts: 553\n",
      "looping 35 time(s). num of posts: 574\n",
      "looping 36 time(s). num of posts: 592\n",
      "looping 37 time(s). num of posts: 616\n",
      "looping 38 time(s). num of posts: 632\n",
      "looping 39 time(s). num of posts: 654\n",
      "looping 40 time(s). num of posts: 666\n",
      "looping 41 time(s). num of posts: 677\n",
      "looping 42 time(s). num of posts: 693\n",
      "looping 43 time(s). num of posts: 708\n",
      "looping 44 time(s). num of posts: 734\n",
      "looping 45 time(s). num of posts: 753\n",
      "looping 46 time(s). num of posts: 769\n",
      "looping 47 time(s). num of posts: 780\n",
      "looping 48 time(s). num of posts: 797\n",
      "looping 49 time(s). num of posts: 808\n",
      "looping 50 time(s). num of posts: 831\n",
      "looping 51 time(s). num of posts: 849\n",
      "looping 52 time(s). num of posts: 870\n",
      "looping 53 time(s). num of posts: 898\n",
      "looping 54 time(s). num of posts: 910\n",
      "looping 55 time(s). num of posts: 927\n",
      "looping 56 time(s). num of posts: 944\n",
      "looping 57 time(s). num of posts: 963\n",
      "looping 58 time(s). num of posts: 978\n",
      "looping 59 time(s). num of posts: 1002\n",
      "looping 60 time(s). num of posts: 1022\n",
      "looping 61 time(s). num of posts: 1040\n",
      "looping 62 time(s). num of posts: 1059\n",
      "looping 63 time(s). num of posts: 1077\n",
      "looping 64 time(s). num of posts: 1097\n",
      "looping 65 time(s). num of posts: 1115\n",
      "looping 66 time(s). num of posts: 1135\n",
      "looping 67 time(s). num of posts: 1163\n",
      "looping 68 time(s). num of posts: 1190\n",
      "looping 69 time(s). num of posts: 1209\n",
      "looping 70 time(s). num of posts: 1231\n",
      "looping 71 time(s). num of posts: 1248\n",
      "looping 72 time(s). num of posts: 1266\n",
      "looping 73 time(s). num of posts: 1286\n",
      "looping 74 time(s). num of posts: 1304\n",
      "looping 75 time(s). num of posts: 1323\n",
      "looping 76 time(s). num of posts: 1343\n",
      "looping 77 time(s). num of posts: 1363\n",
      "looping 78 time(s). num of posts: 1378\n",
      "looping 79 time(s). num of posts: 1403\n",
      "looping 80 time(s). num of posts: 1438\n",
      "looping 81 time(s). num of posts: 1461\n",
      "looping 82 time(s). num of posts: 1482\n",
      "looping 83 time(s). num of posts: 1503\n",
      "looping 84 time(s). num of posts: 1518\n",
      "looping 85 time(s). num of posts: 1534\n",
      "looping 86 time(s). num of posts: 1551\n",
      "looping 87 time(s). num of posts: 1575\n",
      "looping 88 time(s). num of posts: 1600\n",
      "looping 89 time(s). num of posts: 1623\n",
      "looping 90 time(s). num of posts: 1642\n",
      "looping 91 time(s). num of posts: 1662\n",
      "looping 92 time(s). num of posts: 1689\n",
      "looping 93 time(s). num of posts: 1712\n",
      "looping 94 time(s). num of posts: 1736\n",
      "looping 95 time(s). num of posts: 1761\n",
      "looping 96 time(s). num of posts: 1778\n",
      "looping 97 time(s). num of posts: 1796\n",
      "looping 98 time(s). num of posts: 1812\n",
      "looping 99 time(s). num of posts: 1827\n",
      "looping 100 time(s). num of posts: 1854\n",
      "looping 101 time(s). num of posts: 1881\n",
      "looping 102 time(s). num of posts: 1900\n",
      "looping 103 time(s). num of posts: 1913\n",
      "looping 104 time(s). num of posts: 1936\n",
      "looping 105 time(s). num of posts: 1955\n",
      "looping 106 time(s). num of posts: 1971\n",
      "looping 107 time(s). num of posts: 1980\n",
      "looping 108 time(s). num of posts: 2003\n",
      "looping 109 time(s). num of posts: 2024\n",
      "looping 110 time(s). num of posts: 2040\n",
      "looping 111 time(s). num of posts: 2068\n",
      "looping 112 time(s). num of posts: 2110\n",
      "looping 113 time(s). num of posts: 2152\n",
      "looping 114 time(s). num of posts: 2181\n",
      "looping 115 time(s). num of posts: 2204\n",
      "looping 116 time(s). num of posts: 2239\n",
      "looping 117 time(s). num of posts: 2270\n",
      "looping 118 time(s). num of posts: 2297\n",
      "looping 119 time(s). num of posts: 2314\n",
      "looping 120 time(s). num of posts: 2335\n",
      "looping 121 time(s). num of posts: 2362\n",
      "looping 122 time(s). num of posts: 2397\n",
      "looping 123 time(s). num of posts: 2413\n",
      "looping 124 time(s). num of posts: 2425\n",
      "looping 125 time(s). num of posts: 2438\n",
      "looping 126 time(s). num of posts: 2479\n",
      "looping 127 time(s). num of posts: 2510\n",
      "looping 128 time(s). num of posts: 2542\n",
      "looping 129 time(s). num of posts: 2568\n",
      "looping 130 time(s). num of posts: 2592\n",
      "looping 131 time(s). num of posts: 2626\n",
      "looping 132 time(s). num of posts: 2654\n",
      "looping 133 time(s). num of posts: 2694\n",
      "looping 134 time(s). num of posts: 2726\n",
      "looping 135 time(s). num of posts: 2751\n",
      "looping 136 time(s). num of posts: 2767\n",
      "looping 137 time(s). num of posts: 2784\n",
      "looping 138 time(s). num of posts: 2804\n",
      "looping 139 time(s). num of posts: 2818\n",
      "looping 140 time(s). num of posts: 2836\n",
      "looping 141 time(s). num of posts: 2850\n",
      "looping 142 time(s). num of posts: 2869\n",
      "looping 143 time(s). num of posts: 2887\n",
      "looping 144 time(s). num of posts: 2915\n",
      "looping 145 time(s). num of posts: 2935\n",
      "looping 146 time(s). num of posts: 2967\n",
      "looping 147 time(s). num of posts: 2986\n",
      "looping 148 time(s). num of posts: 3008\n",
      "looping 149 time(s). num of posts: 3024\n",
      "looping 150 time(s). num of posts: 3038\n",
      "looping 151 time(s). num of posts: 3058\n",
      "looping 152 time(s). num of posts: 3080\n",
      "looping 153 time(s). num of posts: 3105\n",
      "looping 154 time(s). num of posts: 3136\n",
      "looping 155 time(s). num of posts: 3156\n",
      "looping 156 time(s). num of posts: 3186\n",
      "looping 157 time(s). num of posts: 3220\n",
      "looping 158 time(s). num of posts: 3246\n",
      "looping 159 time(s). num of posts: 3267\n",
      "looping 160 time(s). num of posts: 3295\n",
      "looping 161 time(s). num of posts: 3320\n",
      "looping 162 time(s). num of posts: 3347\n",
      "looping 163 time(s). num of posts: 3368\n",
      "looping 164 time(s). num of posts: 3391\n",
      "looping 165 time(s). num of posts: 3423\n",
      "looping 166 time(s). num of posts: 3449\n",
      "looping 167 time(s). num of posts: 3470\n",
      "looping 168 time(s). num of posts: 3505\n",
      "looping 169 time(s). num of posts: 3537\n",
      "looping 170 time(s). num of posts: 3560\n",
      "looping 171 time(s). num of posts: 3585\n",
      "looping 172 time(s). num of posts: 3614\n",
      "looping 173 time(s). num of posts: 3633\n",
      "looping 174 time(s). num of posts: 3660\n",
      "looping 175 time(s). num of posts: 3688\n",
      "looping 176 time(s). num of posts: 3709\n",
      "looping 177 time(s). num of posts: 3739\n",
      "looping 178 time(s). num of posts: 3767\n",
      "looping 179 time(s). num of posts: 3804\n",
      "looping 180 time(s). num of posts: 3829\n",
      "looping 181 time(s). num of posts: 3856\n",
      "looping 182 time(s). num of posts: 3883\n",
      "looping 183 time(s). num of posts: 3908\n",
      "looping 184 time(s). num of posts: 3935\n",
      "looping 185 time(s). num of posts: 3969\n",
      "looping 186 time(s). num of posts: 3996\n",
      "looping 187 time(s). num of posts: 4027\n",
      "looping 188 time(s). num of posts: 4049\n",
      "looping 189 time(s). num of posts: 4072\n",
      "looping 190 time(s). num of posts: 4091\n",
      "looping 191 time(s). num of posts: 4114\n",
      "looping 192 time(s). num of posts: 4138\n",
      "looping 193 time(s). num of posts: 4157\n",
      "looping 194 time(s). num of posts: 4179\n",
      "looping 195 time(s). num of posts: 4202\n",
      "looping 196 time(s). num of posts: 4225\n",
      "looping 197 time(s). num of posts: 4238\n",
      "looping 198 time(s). num of posts: 4263\n",
      "looping 199 time(s). num of posts: 4281\n",
      "looping 200 time(s). num of posts: 4300\n",
      "looping 201 time(s). num of posts: 4317\n",
      "looping 202 time(s). num of posts: 4333\n",
      "looping 203 time(s). num of posts: 4349\n",
      "looping 204 time(s). num of posts: 4360\n",
      "looping 205 time(s). num of posts: 4372\n",
      "looping 206 time(s). num of posts: 4382\n",
      "looping 207 time(s). num of posts: 4401\n",
      "looping 208 time(s). num of posts: 4411\n",
      "looping 209 time(s). num of posts: 4418\n",
      "looping 210 time(s). num of posts: 4428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looping 211 time(s). num of posts: 4443\n",
      "looping 212 time(s). num of posts: 4458\n",
      "looping 213 time(s). num of posts: 4471\n",
      "looping 214 time(s). num of posts: 4481\n",
      "looping 215 time(s). num of posts: 4490\n",
      "looping 216 time(s). num of posts: 4501\n",
      "looping 217 time(s). num of posts: 4520\n",
      "looping 218 time(s). num of posts: 4528\n",
      "looping 219 time(s). num of posts: 4541\n",
      "looping 220 time(s). num of posts: 4557\n",
      "looping 221 time(s). num of posts: 4573\n",
      "looping 222 time(s). num of posts: 4588\n",
      "looping 223 time(s). num of posts: 4604\n",
      "looping 224 time(s). num of posts: 4612\n",
      "looping 225 time(s). num of posts: 4615\n",
      "looping 226 time(s). num of posts: 4628\n",
      "looping 227 time(s). num of posts: 4640\n",
      "looping 228 time(s). num of posts: 4649\n",
      "looping 229 time(s). num of posts: 4666\n",
      "looping 230 time(s). num of posts: 4682\n",
      "looping 231 time(s). num of posts: 4694\n",
      "looping 232 time(s). num of posts: 4706\n",
      "looping 233 time(s). num of posts: 4727\n",
      "looping 234 time(s). num of posts: 4735\n",
      "looping 235 time(s). num of posts: 4748\n",
      "looping 236 time(s). num of posts: 4763\n",
      "looping 237 time(s). num of posts: 4780\n",
      "looping 238 time(s). num of posts: 4797\n",
      "looping 239 time(s). num of posts: 4806\n",
      "looping 240 time(s). num of posts: 4816\n",
      "looping 241 time(s). num of posts: 4830\n",
      "looping 242 time(s). num of posts: 4842\n",
      "looping 243 time(s). num of posts: 4860\n",
      "looping 244 time(s). num of posts: 4867\n",
      "looping 245 time(s). num of posts: 4880\n",
      "looping 246 time(s). num of posts: 4894\n",
      "looping 247 time(s). num of posts: 4918\n",
      "looping 248 time(s). num of posts: 4930\n",
      "looping 249 time(s). num of posts: 4944\n",
      "looping 250 time(s). num of posts: 4958\n",
      "looping 251 time(s). num of posts: 4969\n",
      "looping 252 time(s). num of posts: 4986\n",
      "looping 253 time(s). num of posts: 4997\n",
      "looping 254 time(s). num of posts: 5012\n",
      "\n",
      "last post scraped is 223 days before 25 Oct.\n",
      "code execution time : 475.71 seconds\n"
     ]
    }
   ],
   "source": [
    "# start time counter\n",
    "start_time = time.time()\n",
    "\n",
    "# initialize and seek the first 100 get requests\n",
    "invest_data = get_push_shift_data('investing', end)\n",
    "\n",
    "# generate an empty list to store the retrieved posts\n",
    "invest_posts = []\n",
    "count = 0\n",
    "\n",
    "# extraction a target of 5000 posts that are not removed or deleted\n",
    "# looping through each extraction process as each pushshift only allows for 100 get requests.\n",
    "while len(invest_posts) < 5000:\n",
    "    \n",
    "    # for each post that are extracted from the get request, extract the relevant columns information\n",
    "    for i in invest_data:\n",
    "        post = extract_posts(i)\n",
    "        \n",
    "        # if the extracted post is not None, i.e. are not deleted or removed, add into the list\n",
    "        if post != None:\n",
    "            invest_posts.append(post)\n",
    "    \n",
    "    # get the time of the 100th post in the get request\n",
    "    last_post = invest_data[len(invest_data)-1]\n",
    "    last_time = post_time(last_post)\n",
    "    \n",
    "    # seek out the next 100 get requests via push shift\n",
    "    invest_data = get_push_shift_data('investing', last_time)\n",
    "    count+=1\n",
    "    \n",
    "    print(f'looping {count} time(s). num of posts: {len(invest_posts)}')\n",
    "\n",
    "print(f'\\nlast post scraped is {(end-last_time)/(60*60*24):.0f} days before 25 Oct.')\n",
    "\n",
    "# print the execution time\n",
    "execution_time = (time.time() - start_time)\n",
    "print(f'code execution time : {execution_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aff17d",
   "metadata": {},
   "source": [
    "Convert the extracted data into a dataframe and preview it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d5d5011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>create</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>permalink</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Great Short Setup on NYSE</td>\n",
       "      <td>1635167989</td>\n",
       "      <td>investing</td>\n",
       "      <td>[Snapshot](https://www.tradingview.com/x/xdfUP...</td>\n",
       "      <td>mildcharts</td>\n",
       "      <td>/r/investing/comments/qfgl43/a_great_short_set...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Great Short Setup on NYSE</td>\n",
       "      <td>1635167785</td>\n",
       "      <td>investing</td>\n",
       "      <td>* Double top on ATH level\\n* Bullish RSI diver...</td>\n",
       "      <td>mildcharts</td>\n",
       "      <td>/r/investing/comments/qfgirk/a_great_short_set...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inherited large amount of equity.. Not sure wh...</td>\n",
       "      <td>1635167216</td>\n",
       "      <td>investing</td>\n",
       "      <td>I'm 25 years old and just inherited a portion ...</td>\n",
       "      <td>EselSchwanz</td>\n",
       "      <td>/r/investing/comments/qfgc31/inherited_large_a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daily General Discussion and spitballin thread...</td>\n",
       "      <td>1635152534</td>\n",
       "      <td>investing</td>\n",
       "      <td>Have a general question?  Want to offer some c...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>/r/investing/comments/qfckhu/daily_general_dis...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daily Advice Thread - All basic help or advice...</td>\n",
       "      <td>1635152476</td>\n",
       "      <td>investing</td>\n",
       "      <td>If your question is \"I have $10,000, what do I...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>/r/investing/comments/qfck11/daily_advice_thre...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      create  subreddit  \\\n",
       "0                        A Great Short Setup on NYSE  1635167989  investing   \n",
       "1                        A Great Short Setup on NYSE  1635167785  investing   \n",
       "2  Inherited large amount of equity.. Not sure wh...  1635167216  investing   \n",
       "3  Daily General Discussion and spitballin thread...  1635152534  investing   \n",
       "4  Daily Advice Thread - All basic help or advice...  1635152476  investing   \n",
       "\n",
       "                                                body         author  \\\n",
       "0  [Snapshot](https://www.tradingview.com/x/xdfUP...     mildcharts   \n",
       "1  * Double top on ATH level\\n* Bullish RSI diver...     mildcharts   \n",
       "2  I'm 25 years old and just inherited a portion ...    EselSchwanz   \n",
       "3  Have a general question?  Want to offer some c...  AutoModerator   \n",
       "4  If your question is \"I have $10,000, what do I...  AutoModerator   \n",
       "\n",
       "                                           permalink  num_comments  \n",
       "0  /r/investing/comments/qfgl43/a_great_short_set...             1  \n",
       "1  /r/investing/comments/qfgirk/a_great_short_set...             1  \n",
       "2  /r/investing/comments/qfgc31/inherited_large_a...             2  \n",
       "3  /r/investing/comments/qfckhu/daily_general_dis...           142  \n",
       "4  /r/investing/comments/qfck11/daily_advice_thre...           101  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert into dataframe\n",
    "invest = pd.DataFrame(invest_posts)\n",
    "# preview data\n",
    "invest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179731da",
   "metadata": {},
   "source": [
    "Take a look at the number of rows and columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb9a4069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5012, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of rows and columns\n",
    "invest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05841ed9",
   "metadata": {},
   "source": [
    "Remove duplicated posts with the same body content.\\\n",
    "Also remove duplicated posts by the same author with the same title. Have noticed that these are duplicated posts even though their body content might not be exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c63527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>create</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>permalink</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Great Short Setup on NYSE</td>\n",
       "      <td>1635167989</td>\n",
       "      <td>investing</td>\n",
       "      <td>[Snapshot](https://www.tradingview.com/x/xdfUP...</td>\n",
       "      <td>mildcharts</td>\n",
       "      <td>/r/investing/comments/qfgl43/a_great_short_set...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inherited large amount of equity.. Not sure wh...</td>\n",
       "      <td>1635167216</td>\n",
       "      <td>investing</td>\n",
       "      <td>I'm 25 years old and just inherited a portion ...</td>\n",
       "      <td>EselSchwanz</td>\n",
       "      <td>/r/investing/comments/qfgc31/inherited_large_a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daily General Discussion and spitballin thread...</td>\n",
       "      <td>1635152534</td>\n",
       "      <td>investing</td>\n",
       "      <td>Have a general question?  Want to offer some c...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>/r/investing/comments/qfckhu/daily_general_dis...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daily Advice Thread - All basic help or advice...</td>\n",
       "      <td>1635152476</td>\n",
       "      <td>investing</td>\n",
       "      <td>If your question is \"I have $10,000, what do I...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>/r/investing/comments/qfck11/daily_advice_thre...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advice on investing and why people overcomplic...</td>\n",
       "      <td>1635140198</td>\n",
       "      <td>investing</td>\n",
       "      <td>Hi guys I'm a 19 year old kid and I've investe...</td>\n",
       "      <td>Worried_individual_</td>\n",
       "      <td>/r/investing/comments/qf9yjv/advice_on_investi...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      create  subreddit  \\\n",
       "0                        A Great Short Setup on NYSE  1635167989  investing   \n",
       "2  Inherited large amount of equity.. Not sure wh...  1635167216  investing   \n",
       "3  Daily General Discussion and spitballin thread...  1635152534  investing   \n",
       "4  Daily Advice Thread - All basic help or advice...  1635152476  investing   \n",
       "5  Advice on investing and why people overcomplic...  1635140198  investing   \n",
       "\n",
       "                                                body               author  \\\n",
       "0  [Snapshot](https://www.tradingview.com/x/xdfUP...           mildcharts   \n",
       "2  I'm 25 years old and just inherited a portion ...          EselSchwanz   \n",
       "3  Have a general question?  Want to offer some c...        AutoModerator   \n",
       "4  If your question is \"I have $10,000, what do I...        AutoModerator   \n",
       "5  Hi guys I'm a 19 year old kid and I've investe...  Worried_individual_   \n",
       "\n",
       "                                           permalink  num_comments  \n",
       "0  /r/investing/comments/qfgl43/a_great_short_set...             1  \n",
       "2  /r/investing/comments/qfgc31/inherited_large_a...             2  \n",
       "3  /r/investing/comments/qfckhu/daily_general_dis...           142  \n",
       "4  /r/investing/comments/qfck11/daily_advice_thre...           101  \n",
       "5  /r/investing/comments/qf9yjv/advice_on_investi...            19  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run through 2 times of duplicates cleaning\n",
    "# first if the rows have same body and author\n",
    "# second if the rows have same title and author\n",
    "invest.drop_duplicates(subset=['body','author'], inplace=True)\n",
    "invest.drop_duplicates(subset=['title','author'], inplace=True)\n",
    "invest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541d4b3",
   "metadata": {},
   "source": [
    "Confirm the removal of duplicates. Check the number of remaining rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa08c356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4533, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31163853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4533 entries, 0 to 5011\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         4533 non-null   object\n",
      " 1   create        4533 non-null   int64 \n",
      " 2   subreddit     4533 non-null   object\n",
      " 3   body          4533 non-null   object\n",
      " 4   author        4533 non-null   object\n",
      " 5   permalink     4533 non-null   object\n",
      " 6   num_comments  4533 non-null   int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 283.3+ KB\n"
     ]
    }
   ],
   "source": [
    "invest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4c144",
   "metadata": {},
   "source": [
    "Export the data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de54cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "invest.to_csv('../data/invest4533.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f1d10",
   "metadata": {},
   "source": [
    "### Scraping subreddit - CryptoCurrency posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed566e",
   "metadata": {},
   "source": [
    "Repeat the process to scrape CryptoCurrency subreddit posts as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e1ab46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looping 1 times. num of posts: 25\n",
      "looping 2 times. num of posts: 58\n",
      "looping 3 times. num of posts: 92\n",
      "looping 4 times. num of posts: 116\n",
      "looping 5 times. num of posts: 147\n",
      "looping 6 times. num of posts: 171\n",
      "looping 7 times. num of posts: 192\n",
      "looping 8 times. num of posts: 219\n",
      "looping 9 times. num of posts: 250\n",
      "looping 10 times. num of posts: 272\n",
      "looping 11 times. num of posts: 295\n",
      "looping 12 times. num of posts: 321\n",
      "looping 13 times. num of posts: 342\n",
      "looping 14 times. num of posts: 371\n",
      "looping 15 times. num of posts: 400\n",
      "looping 16 times. num of posts: 426\n",
      "looping 17 times. num of posts: 454\n",
      "looping 18 times. num of posts: 490\n",
      "looping 19 times. num of posts: 524\n",
      "looping 20 times. num of posts: 557\n",
      "looping 21 times. num of posts: 585\n",
      "looping 22 times. num of posts: 613\n",
      "looping 23 times. num of posts: 641\n",
      "looping 24 times. num of posts: 670\n",
      "looping 25 times. num of posts: 700\n",
      "looping 26 times. num of posts: 735\n",
      "looping 27 times. num of posts: 751\n",
      "looping 28 times. num of posts: 771\n",
      "looping 29 times. num of posts: 798\n",
      "looping 30 times. num of posts: 826\n",
      "looping 31 times. num of posts: 861\n",
      "looping 32 times. num of posts: 893\n",
      "looping 33 times. num of posts: 919\n",
      "looping 34 times. num of posts: 955\n",
      "looping 35 times. num of posts: 975\n",
      "looping 36 times. num of posts: 998\n",
      "looping 37 times. num of posts: 1023\n",
      "looping 38 times. num of posts: 1056\n",
      "looping 39 times. num of posts: 1074\n",
      "looping 40 times. num of posts: 1100\n",
      "looping 41 times. num of posts: 1131\n",
      "looping 42 times. num of posts: 1157\n",
      "looping 43 times. num of posts: 1182\n",
      "looping 44 times. num of posts: 1208\n",
      "looping 45 times. num of posts: 1244\n",
      "looping 46 times. num of posts: 1275\n",
      "looping 47 times. num of posts: 1308\n",
      "looping 48 times. num of posts: 1335\n",
      "looping 49 times. num of posts: 1361\n",
      "looping 50 times. num of posts: 1385\n",
      "looping 51 times. num of posts: 1411\n",
      "looping 52 times. num of posts: 1437\n",
      "looping 53 times. num of posts: 1468\n",
      "looping 54 times. num of posts: 1498\n",
      "looping 55 times. num of posts: 1525\n",
      "looping 56 times. num of posts: 1545\n",
      "looping 57 times. num of posts: 1571\n",
      "looping 58 times. num of posts: 1596\n",
      "looping 59 times. num of posts: 1615\n",
      "looping 60 times. num of posts: 1641\n",
      "looping 61 times. num of posts: 1669\n",
      "looping 62 times. num of posts: 1690\n",
      "looping 63 times. num of posts: 1722\n",
      "looping 64 times. num of posts: 1748\n",
      "looping 65 times. num of posts: 1776\n",
      "looping 66 times. num of posts: 1811\n",
      "looping 67 times. num of posts: 1836\n",
      "looping 68 times. num of posts: 1862\n",
      "looping 69 times. num of posts: 1883\n",
      "looping 70 times. num of posts: 1905\n",
      "looping 71 times. num of posts: 1923\n",
      "looping 72 times. num of posts: 1953\n",
      "looping 73 times. num of posts: 1996\n",
      "looping 74 times. num of posts: 2023\n",
      "looping 75 times. num of posts: 2053\n",
      "looping 76 times. num of posts: 2081\n",
      "looping 77 times. num of posts: 2110\n",
      "looping 78 times. num of posts: 2135\n",
      "looping 79 times. num of posts: 2156\n",
      "looping 80 times. num of posts: 2181\n",
      "looping 81 times. num of posts: 2203\n",
      "looping 82 times. num of posts: 2226\n",
      "looping 83 times. num of posts: 2259\n",
      "looping 84 times. num of posts: 2291\n",
      "looping 85 times. num of posts: 2311\n",
      "looping 86 times. num of posts: 2333\n",
      "looping 87 times. num of posts: 2363\n",
      "looping 88 times. num of posts: 2386\n",
      "looping 89 times. num of posts: 2417\n",
      "looping 90 times. num of posts: 2449\n",
      "looping 91 times. num of posts: 2484\n",
      "looping 92 times. num of posts: 2509\n",
      "looping 93 times. num of posts: 2533\n",
      "looping 94 times. num of posts: 2563\n",
      "looping 95 times. num of posts: 2597\n",
      "looping 96 times. num of posts: 2615\n",
      "looping 97 times. num of posts: 2645\n",
      "looping 98 times. num of posts: 2666\n",
      "looping 99 times. num of posts: 2684\n",
      "looping 100 times. num of posts: 2706\n",
      "looping 101 times. num of posts: 2733\n",
      "looping 102 times. num of posts: 2764\n",
      "looping 103 times. num of posts: 2787\n",
      "looping 104 times. num of posts: 2813\n",
      "looping 105 times. num of posts: 2842\n",
      "looping 106 times. num of posts: 2875\n",
      "looping 107 times. num of posts: 2900\n",
      "looping 108 times. num of posts: 2933\n",
      "looping 109 times. num of posts: 2959\n",
      "looping 110 times. num of posts: 2993\n",
      "looping 111 times. num of posts: 3025\n",
      "looping 112 times. num of posts: 3053\n",
      "looping 113 times. num of posts: 3081\n",
      "looping 114 times. num of posts: 3103\n",
      "looping 115 times. num of posts: 3138\n",
      "looping 116 times. num of posts: 3157\n",
      "looping 117 times. num of posts: 3189\n",
      "looping 118 times. num of posts: 3216\n",
      "looping 119 times. num of posts: 3236\n",
      "looping 120 times. num of posts: 3257\n",
      "looping 121 times. num of posts: 3284\n",
      "looping 122 times. num of posts: 3315\n",
      "looping 123 times. num of posts: 3338\n",
      "looping 124 times. num of posts: 3361\n",
      "looping 125 times. num of posts: 3391\n",
      "looping 126 times. num of posts: 3411\n",
      "looping 127 times. num of posts: 3447\n",
      "looping 128 times. num of posts: 3481\n",
      "looping 129 times. num of posts: 3509\n",
      "looping 130 times. num of posts: 3532\n",
      "looping 131 times. num of posts: 3565\n",
      "looping 132 times. num of posts: 3588\n",
      "looping 133 times. num of posts: 3615\n",
      "looping 134 times. num of posts: 3645\n",
      "looping 135 times. num of posts: 3676\n",
      "looping 136 times. num of posts: 3702\n",
      "looping 137 times. num of posts: 3717\n",
      "looping 138 times. num of posts: 3740\n",
      "looping 139 times. num of posts: 3763\n",
      "looping 140 times. num of posts: 3789\n",
      "looping 141 times. num of posts: 3813\n",
      "looping 142 times. num of posts: 3845\n",
      "looping 143 times. num of posts: 3878\n",
      "looping 144 times. num of posts: 3912\n",
      "looping 145 times. num of posts: 3946\n",
      "looping 146 times. num of posts: 3975\n",
      "looping 147 times. num of posts: 4002\n",
      "looping 148 times. num of posts: 4041\n",
      "looping 149 times. num of posts: 4074\n",
      "looping 150 times. num of posts: 4101\n",
      "looping 151 times. num of posts: 4138\n",
      "looping 152 times. num of posts: 4171\n",
      "looping 153 times. num of posts: 4203\n",
      "looping 154 times. num of posts: 4230\n",
      "looping 155 times. num of posts: 4259\n",
      "looping 156 times. num of posts: 4290\n",
      "looping 157 times. num of posts: 4325\n",
      "looping 158 times. num of posts: 4354\n",
      "looping 159 times. num of posts: 4391\n",
      "looping 160 times. num of posts: 4416\n",
      "looping 161 times. num of posts: 4449\n",
      "looping 162 times. num of posts: 4481\n",
      "looping 163 times. num of posts: 4503\n",
      "looping 164 times. num of posts: 4533\n",
      "looping 165 times. num of posts: 4567\n",
      "looping 166 times. num of posts: 4598\n",
      "looping 167 times. num of posts: 4630\n",
      "looping 168 times. num of posts: 4668\n",
      "looping 169 times. num of posts: 4700\n",
      "looping 170 times. num of posts: 4739\n",
      "looping 171 times. num of posts: 4765\n",
      "looping 172 times. num of posts: 4783\n",
      "looping 173 times. num of posts: 4816\n",
      "looping 174 times. num of posts: 4844\n",
      "looping 175 times. num of posts: 4883\n",
      "looping 176 times. num of posts: 4909\n",
      "looping 177 times. num of posts: 4931\n",
      "looping 178 times. num of posts: 4960\n",
      "looping 179 times. num of posts: 4995\n",
      "looping 180 times. num of posts: 5025\n",
      "\n",
      "last post scraped is 10 days before 25 Oct.\n",
      "code execution time : 402.46 seconds\n"
     ]
    }
   ],
   "source": [
    "# start time counter\n",
    "start_time = time.time()\n",
    "\n",
    "# initialize and seek the first 100 get requests\n",
    "crypto_data = get_push_shift_data('CryptoCurrency', end)\n",
    "\n",
    "# generate an empty list to store the retrieved posts\n",
    "crypto_posts = []\n",
    "count = 0\n",
    "\n",
    "# extraction a target of 5000 posts that are not removed or deleted\n",
    "# looping through each extraction process as each pushshift only allows for 100 get requests.\n",
    "while len(crypto_posts) < 5000:\n",
    "    \n",
    "    # for each post that are extracted from the get request, extract the relevant columns information\n",
    "    for i in crypto_data:\n",
    "        post = extract_posts(i)\n",
    "        \n",
    "        # if the extracted post is not None, i.e. are not deleted or removed, add into the list\n",
    "        if post != None:\n",
    "            crypto_posts.append(post)\n",
    "    \n",
    "    # get the time of the 100th post in the get request\n",
    "    last_post = crypto_data[len(crypto_data)-1]\n",
    "    last_time = post_time(last_post)\n",
    "    \n",
    "    # seek out the next 100 get requests via push shift\n",
    "    crypto_data = get_push_shift_data('CryptoCurrency', last_time)\n",
    "    count+=1\n",
    "    \n",
    "    print(f'looping {count} times. num of posts: {len(crypto_posts)}')\n",
    "\n",
    "print(f'\\nlast post scraped is {(end-last_time)/(60*60*24):.0f} days before 25 Oct.')\n",
    "\n",
    "# print the execution time\n",
    "execution_time = (time.time() - start_time)\n",
    "print(f'code execution time : {execution_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bad138",
   "metadata": {},
   "source": [
    "Convert the extracted data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d845d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>create</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>permalink</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is Binance afraid of Crypto.com?</td>\n",
       "      <td>1635177574</td>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>So I have to assume as the title says above. I...</td>\n",
       "      <td>Markmanus</td>\n",
       "      <td>/r/CryptoCurrency/comments/qfjw21/is_binance_a...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's been your worst move in Crypto? (So far)</td>\n",
       "      <td>1635177350</td>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>We've all made silly mistakes since our incept...</td>\n",
       "      <td>frostybitz</td>\n",
       "      <td>/r/CryptoCurrency/comments/qfjt5m/whats_been_y...</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IRS wants to monitor your bank account flow. T...</td>\n",
       "      <td>1635177349</td>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>Ok so I'll start with the article link from NP...</td>\n",
       "      <td>Mediocre-Sale8473</td>\n",
       "      <td>/r/CryptoCurrency/comments/qfjt5b/irs_wants_to...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Financial Lifehacks To Get Extra Money for Buy...</td>\n",
       "      <td>1635177185</td>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>Hello there do you wish you could put some mor...</td>\n",
       "      <td>Many_Arm7466</td>\n",
       "      <td>/r/CryptoCurrency/comments/qfjr0v/financial_li...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Want to earn some extra Crypto on the side? Ch...</td>\n",
       "      <td>1635177106</td>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>Check out the best play-to-earn crypto game on...</td>\n",
       "      <td>silver_sean</td>\n",
       "      <td>/r/CryptoCurrency/comments/qfjq0i/want_to_earn...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      create  \\\n",
       "0                   Is Binance afraid of Crypto.com?  1635177574   \n",
       "1    What's been your worst move in Crypto? (So far)  1635177350   \n",
       "2  IRS wants to monitor your bank account flow. T...  1635177349   \n",
       "3  Financial Lifehacks To Get Extra Money for Buy...  1635177185   \n",
       "4  Want to earn some extra Crypto on the side? Ch...  1635177106   \n",
       "\n",
       "        subreddit                                               body  \\\n",
       "0  CryptoCurrency  So I have to assume as the title says above. I...   \n",
       "1  CryptoCurrency  We've all made silly mistakes since our incept...   \n",
       "2  CryptoCurrency  Ok so I'll start with the article link from NP...   \n",
       "3  CryptoCurrency  Hello there do you wish you could put some mor...   \n",
       "4  CryptoCurrency  Check out the best play-to-earn crypto game on...   \n",
       "\n",
       "              author                                          permalink  \\\n",
       "0          Markmanus  /r/CryptoCurrency/comments/qfjw21/is_binance_a...   \n",
       "1         frostybitz  /r/CryptoCurrency/comments/qfjt5m/whats_been_y...   \n",
       "2  Mediocre-Sale8473  /r/CryptoCurrency/comments/qfjt5b/irs_wants_to...   \n",
       "3       Many_Arm7466  /r/CryptoCurrency/comments/qfjr0v/financial_li...   \n",
       "4        silver_sean  /r/CryptoCurrency/comments/qfjq0i/want_to_earn...   \n",
       "\n",
       "   num_comments  \n",
       "0            51  \n",
       "1           205  \n",
       "2            12  \n",
       "3            17  \n",
       "4             7  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto = pd.DataFrame(crypto_posts)\n",
    "crypto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648398a",
   "metadata": {},
   "source": [
    "Take a look at the number of rows and columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "babb92fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5025, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b28ba",
   "metadata": {},
   "source": [
    "Likewise, remove duplicated posts with the same body content.\\\n",
    "Also remove duplicated posts by the same author with the same title. Have noticed that these are duplicated posts even though their body content might not be exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daafcbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>create</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>permalink</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is Binance afraid of Crypto.com?</td>\n",
       "      <td>1635177574</td>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>So I have to assume as the title says above. I...</td>\n",
       "      <td>Markmanus</td>\n",
       "      <td>/r/CryptoCurrency/comments/qfjw21/is_binance_a...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's been your worst move in Crypto? (So far)</td>\n",
       "      <td>1635177350</td>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>We've all made silly mistakes since our incept...</td>\n",
       "      <td>frostybitz</td>\n",
       "      <td>/r/CryptoCurrency/comments/qfjt5m/whats_been_y...</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IRS wants to monitor your bank account flow. T...</td>\n",
       "      <td>1635177349</td>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>Ok so I'll start with the article link from NP...</td>\n",
       "      <td>Mediocre-Sale8473</td>\n",
       "      <td>/r/CryptoCurrency/comments/qfjt5b/irs_wants_to...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Financial Lifehacks To Get Extra Money for Buy...</td>\n",
       "      <td>1635177185</td>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>Hello there do you wish you could put some mor...</td>\n",
       "      <td>Many_Arm7466</td>\n",
       "      <td>/r/CryptoCurrency/comments/qfjr0v/financial_li...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Want to earn some extra Crypto on the side? Ch...</td>\n",
       "      <td>1635177106</td>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>Check out the best play-to-earn crypto game on...</td>\n",
       "      <td>silver_sean</td>\n",
       "      <td>/r/CryptoCurrency/comments/qfjq0i/want_to_earn...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      create  \\\n",
       "0                   Is Binance afraid of Crypto.com?  1635177574   \n",
       "1    What's been your worst move in Crypto? (So far)  1635177350   \n",
       "2  IRS wants to monitor your bank account flow. T...  1635177349   \n",
       "3  Financial Lifehacks To Get Extra Money for Buy...  1635177185   \n",
       "4  Want to earn some extra Crypto on the side? Ch...  1635177106   \n",
       "\n",
       "        subreddit                                               body  \\\n",
       "0  CryptoCurrency  So I have to assume as the title says above. I...   \n",
       "1  CryptoCurrency  We've all made silly mistakes since our incept...   \n",
       "2  CryptoCurrency  Ok so I'll start with the article link from NP...   \n",
       "3  CryptoCurrency  Hello there do you wish you could put some mor...   \n",
       "4  CryptoCurrency  Check out the best play-to-earn crypto game on...   \n",
       "\n",
       "              author                                          permalink  \\\n",
       "0          Markmanus  /r/CryptoCurrency/comments/qfjw21/is_binance_a...   \n",
       "1         frostybitz  /r/CryptoCurrency/comments/qfjt5m/whats_been_y...   \n",
       "2  Mediocre-Sale8473  /r/CryptoCurrency/comments/qfjt5b/irs_wants_to...   \n",
       "3       Many_Arm7466  /r/CryptoCurrency/comments/qfjr0v/financial_li...   \n",
       "4        silver_sean  /r/CryptoCurrency/comments/qfjq0i/want_to_earn...   \n",
       "\n",
       "   num_comments  \n",
       "0            51  \n",
       "1           205  \n",
       "2            12  \n",
       "3            17  \n",
       "4             7  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto.drop_duplicates(subset=['body','author'], inplace=True)\n",
    "crypto.drop_duplicates(subset=['title','author'], inplace=True)\n",
    "\n",
    "crypto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb1768",
   "metadata": {},
   "source": [
    "Confirm the removal of duplicates. Check the number of remaining rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "240849e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4888, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5c934ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4888 entries, 0 to 5024\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         4888 non-null   object\n",
      " 1   create        4888 non-null   int64 \n",
      " 2   subreddit     4888 non-null   object\n",
      " 3   body          4888 non-null   object\n",
      " 4   author        4888 non-null   object\n",
      " 5   permalink     4888 non-null   object\n",
      " 6   num_comments  4888 non-null   int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 305.5+ KB\n"
     ]
    }
   ],
   "source": [
    "crypto.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8124feb",
   "metadata": {},
   "source": [
    "Export the data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc34de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto.to_csv('../data/crypto4888.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12782688",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "|  Feature  |  Type  |  Dataset  |  Description  |\n",
    "|:----------|:------:|:---------:|:--------------|\n",
    "| title     | object | invest    | The title of the subreddit post|\n",
    "| create    | int    | invest    | The time that the reddit post was created in epoch unix units|\n",
    "| subreddit | object | invest    | The subreddit that the post belongs to |\n",
    "| body      | object | invest    | The body contents of the reddit post |\n",
    "| author    | object | invest    | The author of the reddit post |\n",
    "| permalink | object | invest    | The url link of the reddit post |\n",
    "| num_comments | object | invest | The number of comments for the reddit post |\n",
    "| title     | object | crypto    | The title of the subreddit post|\n",
    "| create    | int    | crypto    | The time that the reddit post was created in epoch unix units|\n",
    "| subreddit | object | crypto    | The subreddit that the post belongs to |\n",
    "| body      | object | crypto    | The body contents of the reddit post |\n",
    "| author    | object | crypto    | The author of the reddit post |\n",
    "| permalink | object | crypto    | The url link of the reddit post |\n",
    "| num_comments | object | crypto | The number of comments for the reddit post |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
